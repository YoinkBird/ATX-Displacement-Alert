
# import numpy as np
import pandas as pd
import json
import pprint as pp
import re
import os,sys

# hard-coded globals
resource_dir = "output"
if __name__ == '__main__':
    # global options
    options = {
            'graphics' : 0, # 0 - disable, 1 - enable
            'verbose' : 0, # -1 - absolutely silent 0 - minimal info, 1+ - increasing levels
            }


    # src: https://docs.python.org/3/howto/argparse.html#id1
    import argparse
    # if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--graphics', type=int, default=0) # action="store_true", default=False)
    parser.add_argument('--verbose', type=int, default=0)
    args = parser.parse_args()
    # "args" defined with 'default=<>', no need for a conditional
    options['graphics'] = args.graphics
    options['verbose'] = args.verbose


def print_test(*args):
    print("####################")
    print("SELF-TEST: %s" % args)
    print("--------------------")
    return("hi")

# open and return loaded json file
def retrieve_json_file(filename, **options):
    import json
    verbose = options['verbose']

    # TODO: convert this, want to force everything in one dir. tmp:
    # filepath=("%s/%s" % (resource_dir, filename))
    filepath = filename
    if( verbose >= 1):
        print("" + filepath)

    # open file as json
    loadedjson = str()
    with open(filepath, 'r') as infile:
       loadedjson = json.load(infile)

    # return native object
    return loadedjson

# DUPLICATE from server.py
# save json to file for consumption by whatever else needs it
def save_json_file(response_json, filename, **options):
    verbose = options['verbose']
    if( verbose >= 1):
        print("# save to file")
    # tmp:
    # filepath=("%s/%s" % (resource_dir, filename))
    filepath = filename
    # if ( quiet != 1):
    #     print("mock-response sending to : " + filepath)
    with open(filepath, 'w') as outfile:
       json.dump(response_json, outfile)

    return filename

def convert_block_groups_geojson_to_geoid_lut(geoid_data,**options):
    '''
    Purpose: generate LUT (look up table) of GEOIDs => polygons based on the block-groups.geojson file

    # Format:
     {
     "type": "FeatureCollection",
     "crs": { "type": "name", "properties": { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } },
     "features": [
         { "type": "Feature",
           "properties":
               { "GEOID": "480139604021",
               #...
               }, 
      { 
        "type": "Polygon", 
        "coordinates": 
        [ [ 
          [ -98.484237, 28.957106 ], 
               #...
        ] ] 
       }, 

    i.e.
    geoidval = data['features'][0][properties][GEOID]
    polygon  = data['features'][0]['geometry']['coordinates']
    '''
    lut_dict = {}
    for index, feature in enumerate( geoid_data['features'] ):
        geoidval = feature['properties']['GEOID']
        # TODO: pass-through the value for Polygon
        #if ( feature['geometry']['type'] == "Polygon" ):
        if ( re.match(r"%s" % ".*Polygon.*", feature['geometry']['type']) ):

            lut_dict[ geoidval ] = {}
            lut_dict[ geoidval ]['geometry'] = {}
            lut_dict[ geoidval ]['geometry'] = feature['geometry']
        else:
            print("ERROR: missing entry Polygon on line %s" % (index))
            print(json.dumps( feature ))
            # TODO: this is bad, throw exception instead
            sys.exit()
            # TODO: placeholder for when proper error handling implemented
            return
    return lut_dict

def get_polygon_by_geoid( target_geoid, geoid_lut,**options):
    '''
    Purpose: return polygon definition for a geoid
    '''
    target_geoid = str(target_geoid)
    if( target_geoid not in geoid_lut ): 
        print("ERROR: GEOID %s not found in lookup table" % (target_geoid))
        # TODO: this is bad, throw exception instead
        #+ for now, just ignoring
        # sys.exit()
        # TODO: placeholder for when proper error handling implemented
        return
    else: 
        # from convert_block_groups_geojson_to_geoid_lut :
        #+ lut_dict[ geoidval ]['geometry'] = feature['geometry']
        return geoid_lut[ target_geoid ]['geometry']


# insert js into html templates
def generate_js_page(geojson):
  # Creating a javascript file to be included
  headV="""var blocks = {
  "type": "FeatureCollection",
  "crs": { "type": "name", "properties": { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } },
"""

  tailV='}'
  scriptData="<!-- data_source: autogenerated -->\n%s\n<!-- data_source: done-->" % geojson
  js_file = "%s\n%s\n%s" % (headV, scriptData , tailV )
  return js_file

def write_file(htmlpage, filename='output.html'):
  # Write out 
  f=open(filename,'w')
  f.write(htmlpage)
  f.close()

def get_score_mock():
    from random import randint
    return randint(0, 99)

if(__name__ == '__main__'):
    #print_test()
    input_json_path="res/samples" + "/" + "geojson_blockgroup_lut.json"
    output_json_path="t/tmp/jsontest" + "/" + "out.json"
    in_json = retrieve_json_file(input_json_path, **options)
    print_test("see the loaded json:")
    print(json.dumps(in_json))
    print_test("dumping to file the json:")
    save_json_file(in_json, output_json_path, **options)
    # verify stored by loading and dumping
    print(json.dumps(
            retrieve_json_file(output_json_path, **options)
        ))


    # Test the geojson_blockgroup_lut table
    #+ create from sample
    #+ dump to file
    testdef_geoid_simple=0
    opt_generate_lut_file=0
    print_test("geoid LUT - create")

    geoid_path="res/samples"
    if(testdef_geoid_simple == 1):
        geoid_path=geoid_path + "/" "block-groups_entries_three.geojson"
    else:
        geoid_path=geoid_path + "/" "block-groups.geojson"
    output_geoid_lut_path = "t/tmp/geoidtest" + "/" + "geoid_lut.json"
    if( opt_generate_lut_file == 1 ):
        # TODO: validate the number of entries
        # create and dump
        # debug - file is large!
        tmpgeoiddata = retrieve_json_file(geoid_path, **options)
        # ^^^ debug ^^^ 
        print("status: loaded raw geoid data");
        geoid_lut_created = convert_block_groups_geojson_to_geoid_lut(
                 #retrieve_json_file(geoid_path, **options),
                 tmpgeoiddata,
                 **options)
        # vvvv no need, verifying from file load vvvv
        # print(json.dumps( geoid_lut_created ))
        print("status: dumping to file %s" % (output_geoid_lut_path) );
        save_json_file(geoid_lut_created, output_geoid_lut_path, **options)
    else:
        print("SKIPPING ...")
    # load and verify
    print("Loading LUT from file output_geoid_lut_path")
    if(testdef_geoid_simple == 1):
        print(json.dumps(
            retrieve_json_file(output_geoid_lut_path, **options),
            ))
    # pp.pprint(
    #         convert_block_groups_geojson_to_geoid_lut(
    #         retrieve_json_file(geoid_path, **options), **options)
    #             )
    print_test("geoid LUT - load")
    sample_geod = "480139604021"
    sample_geod = "484530000000"
    sample_geod = "484530013041"
    # MultiPolygon
    sample_geod = "480079501001"
    # TODO: load from file
    geoid_lut_loaded = retrieve_json_file(output_geoid_lut_path, **options)
    outpoly = get_polygon_by_geoid( sample_geod, geoid_lut_loaded, **options)
    pp.pprint( outpoly )

    ######################################## 
    # Add the polygons to some data

    opt_add_polygons=1
    print_test("adding polygons to geoid from LUT")

    data_with_geoid_basedir="res/samples"
    data_with_geoid="ConstructionDataGeocodeATX_py_entries_10.csv"
    data_with_geoid_path="%s/%s" % (data_with_geoid_basedir, data_with_geoid)
    output_path_for_web_js="t/tmp/webgentest" + "/" + "out.js"
    output_path_for_web_json="t/tmp/webgentest" + "/" + "out.json"

    if( opt_add_polygons == 1 ):
        # load the input data
        datafile = data_with_geoid_path
        data_in = pd.read_csv(datafile,header=0)

        # load the polygons
        # TODO, done above

        # get to it
        #IDK tmpser = pd.Series( index=data_in.index )
        '''
        '''
        features_out = []
        for i,ser in data_in.iterrows():
            dict_out = {}
            dict_out['type'] = "Feature"
            dict_out['properties'] = {}
            dict_out['geometry'] = {}
            #dict_out['geometry']["coordinates"] = {}
#            print(i)
#            print(ser['BlockGroupCode'])
            outpoly = get_polygon_by_geoid( ser['BlockGroupCode'], geoid_lut_loaded, **options)
            # skip the unresolved geoids
            # TODO: use proper np.nan
            if( outpoly ):
                dict_out['properties']['GEOID'] = ser['BlockGroupCode']
                # TODO: get the score from the DF instead
                #+ dict_out['properties']['risk_score'] = ser['risk_score']
                dict_out['properties']['risk_score'] = get_score_mock()
                # TODO: MultiPolygon !
                # dict_out['geometry']['type'] = "Polygon"
                dict_out['geometry']['type'] = outpoly['type']
                dict_out['geometry']["coordinates"] = outpoly
                features_out.append(dict_out)
            # dict approach - didn't work, needed more time to trick pandas
            # data_in.ix[i]['polygram']=outpoly
            #IDK tmpser[i] = outpoly
#            print("")

        save_json_file(features_out,output_path_for_web_json, **options)
        # generate page
        jspage = generate_js_page( 
                json.dumps(
                    features_out))
        write_file( jspage, output_path_for_web_js )
        
        print("")


    else:
        print("SKIPPING ...")
       

